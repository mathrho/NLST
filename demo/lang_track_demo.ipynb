{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import skimage.io\n",
    "import numpy as np\n",
    "import caffe\n",
    "import json\n",
    "import cv2\n",
    "import time\n",
    "from glob import glob, iglob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "sys.path.append('../')\n",
    "sys.path.append('../track_model')\n",
    "\n",
    "from track_model import track_model_test as trackmodel\n",
    "from util import processing_tools, im_processing, text_processing, eval_tools\n",
    "import demo_track_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# Load config\n",
    "config = demo_track_config.Config()\n",
    "\n",
    "# Load the model\n",
    "with open('./demo_track_features.prototxt', 'w') as f:\n",
    "    f.write(str(trackmodel.generate_conv_features('val', config)))\n",
    "with open('./demo_track_scores.prototxt', 'w') as f:\n",
    "    f.write(str(trackmodel.generate_conv_scores('val', config)))\n",
    "\n",
    "caffe.set_device(config.gpu_id)\n",
    "caffe.set_mode_gpu()\n",
    "\n",
    "# Load pretrained model\n",
    "conv_features_net = caffe.Net('./demo_track_features.prototxt',\n",
    "                              config.pretrained_model,\n",
    "                              caffe.TEST)\n",
    "conv_scores_net = caffe.Net('./demo_track_scores.prototxt',\n",
    "                       config.pretrained_model,\n",
    "                       caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhenyang/anaconda2/lib/python2.7/site-packages/skimage/util/dtype.py:110: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  \"%s to %s\" % (dtypeobj_in, dtypeobj))\n"
     ]
    }
   ],
   "source": [
    "# input image and query box\n",
    "#video_name = 'Bebop2_drone'\n",
    "video_name = 'woman'\n",
    "video_file = './demo_data/%s/*.jpg' % (video_name)\n",
    "query_box = np.loadtxt('./demo_results/%s/0001_pred.txt' % (video_name), delimiter=',').reshape((-1, 4))\n",
    "\n",
    "# query box\n",
    "init_box = query_box[0,:].copy()\n",
    "init_box_w = init_box[2] - init_box[0] + 1\n",
    "init_box_h = init_box[3] - init_box[1] + 1\n",
    "\n",
    "# load query image (first frame)\n",
    "qimg = skimage.io.imread('./demo_data/%s/0001.jpg' % (video_name))\n",
    "\n",
    "if qimg.ndim == 2:\n",
    "    qimg = np.tile(qimg[:, :, np.newaxis], (1, 1, 3))\n",
    "qimg_height, qimg_width = qimg.shape[:2]\n",
    "\n",
    "# select the triple larger box to include some context\n",
    "qbox = init_box.copy()\n",
    "qbox[0] = qbox[0] - 1.0*init_box_w\n",
    "qbox[1] = qbox[1] - 1.0*init_box_h\n",
    "qbox[2] = qbox[2] + 1.0*init_box_w\n",
    "qbox[3] = qbox[3] + 1.0*init_box_h\n",
    "qbox = np.round(qbox).astype(int).reshape((-1, 4))\n",
    "\n",
    "# extract query box features\n",
    "dummy_label = np.zeros((config.N, 1))\n",
    "inputs = np.zeros((config.N, config.query_H, config.query_W, 3), dtype=np.float32)\n",
    "inputs[0, ...] = im_processing.crop_and_pad_bboxes_subtract_mean(\n",
    "                    qimg, qbox, config.qimage_size*3, trackmodel.channel_mean)\n",
    "inputs_trans = inputs.transpose((0, 3, 1, 2))\n",
    "inputs_trans = inputs_trans[:, ::-1, :, :]\n",
    "conv_features_net.blobs['image'].data[...] = inputs_trans\n",
    "conv_features_net.blobs['label'].data[...] = dummy_label\n",
    "conv_features_net.forward()\n",
    "conv_features = conv_features_net.blobs['feat_all'].data[...].copy()\n",
    "\n",
    "# crop feature map\n",
    "qfeat = conv_features[0, ...].copy()\n",
    "qfeat_crop = im_processing.crop_featmap_from_center(qfeat, 3.0)\n",
    "qfeat_crop_resh = qfeat_crop.reshape((-1, qfeat_crop.shape[0], qfeat_crop.shape[1], qfeat_crop.shape[2]))\n",
    "\n",
    "# set up dyn filters\n",
    "#print('params nr %d'%(len(conv_scores_net.params['scores']), ))\n",
    "conv_scores_net.params['scores'][0].data[...] = qfeat_crop_resh\n",
    "\n",
    "################################################################################\n",
    "# Start tracking target on each frame\n",
    "################################################################################\n",
    "query_bbox = np.copy(qimg)\n",
    "cv2.rectangle(query_bbox, (int(init_box[0]-1), int(init_box[1]-1)), (int(init_box[2]-1), int(init_box[3]-1)), (255, 0, 0), 3)\n",
    "plt.imsave('./demo_results/%s/0001_initial.jpg' % (video_name), query_bbox)\n",
    "    \n",
    "start_frame_id = 1\n",
    "frames = sorted(glob(video_file))\n",
    "num_frames = min(len(frames), 500)\n",
    "\n",
    "results = np.zeros((num_frames, 5))\n",
    "results[0, 0] = 1\n",
    "results[0, 1:] = init_box\n",
    "\n",
    "center_x = np.ceil((init_box[2]-init_box[0]+1)/2.0) + init_box[0] - 1\n",
    "center_y = np.ceil((init_box[3]-init_box[1]+1)/2.0) + init_box[1] - 1\n",
    "\n",
    "sz_times = config.sz_times\n",
    "sample_w = init_box_w\n",
    "sample_h = init_box_h\n",
    "\n",
    "prev_scale = 1\n",
    "counter = 1\n",
    "start_time = time.time()\n",
    "for ii in range(start_frame_id+1, num_frames+start_frame_id):\n",
    "    img = skimage.io.imread('./demo_data/%s/%04d.jpg' % (video_name, ii))\n",
    "    if img.ndim == 2:\n",
    "        img = np.tile(img[:, :, np.newaxis], (1, 1, 3))\n",
    "    img_height, img_width = img.shape[:2]\n",
    "\n",
    "    # assemble box proposals with multiple scales\n",
    "    boxes = np.zeros((config.scales.size, 4))\n",
    "    for ss, scale in enumerate(config.scales):\n",
    "        boxes[ss, 0] = center_x - 0.5*sz_times*scale*sample_w + 1\n",
    "        boxes[ss, 1] = center_y - 0.5*sz_times*scale*sample_h + 1\n",
    "        boxes[ss, 2] = center_x + 0.5*sz_times*scale*sample_w\n",
    "        boxes[ss, 3] = center_y + 0.5*sz_times*scale*sample_h\n",
    "    boxes = np.round(boxes).astype(int).reshape((-1, 4))\n",
    "    num_boxes = boxes.shape[0]\n",
    "\n",
    "    # extract query box features\n",
    "    inputs = np.zeros((config.N, config.input_H, config.input_W, 3), dtype=np.float32)\n",
    "    inputs[:num_boxes, ...] = im_processing.crop_and_pad_bboxes_subtract_mean(\n",
    "                                 img, boxes, config.timage_size, trackmodel.channel_mean)\n",
    "    inputs_trans = inputs.transpose((0, 3, 1, 2))\n",
    "    inputs_trans = inputs_trans[:, ::-1, :, :]\n",
    "    conv_scores_net.blobs['image'].data[...] = inputs_trans\n",
    "    conv_scores_net.blobs['label'].data[...] = dummy_label\n",
    "    conv_scores_net.forward()\n",
    "    scores_val = conv_scores_net.blobs['scores'].data[...].copy()\n",
    "    scores_val = scores_val[:num_boxes, ...]\n",
    "\n",
    "    # obtain sizes\n",
    "    map_h = scores_val.shape[2]\n",
    "    map_w = scores_val.shape[3]\n",
    "    map_size = map_h * map_w\n",
    "\n",
    "    # scale change penalty\n",
    "    scores_val = np.multiply(scores_val, config.scale_penalty)\n",
    "    scores_val = scores_val.reshape(-1)\n",
    "\n",
    "    max_idx = np.argmax(scores_val)+1\n",
    "    max_score = scores_val[max_idx-1]\n",
    "    s_idx = np.ceil(float(max_idx)/map_size)\n",
    "    max_idx_within = np.fmod(max_idx,map_size)\n",
    "    r_idx = 0\n",
    "    c_idx = 0\n",
    "    if max_idx_within == 0:\n",
    "        r_idx = map_h\n",
    "        c_idx = map_w\n",
    "    else:\n",
    "        r_idx = np.ceil(float(max_idx_within)/map_w)\n",
    "        c_idx = np.fmod(max_idx_within,map_w)\n",
    "        if c_idx == 0:\n",
    "            c_idx = map_w\n",
    "\n",
    "    # obtain box prediction\n",
    "    bbox = boxes[int(s_idx-1), :].copy()\n",
    "    predict_box = bbox.copy()\n",
    "    predict_box[0] = np.maximum(bbox[0] + (c_idx-1-5) * config.spatial_ratio / config.timage_size * (bbox[2]-bbox[0]+1), 1)\n",
    "    predict_box[1] = np.maximum(bbox[1] + (r_idx-1-5) * config.spatial_ratio / config.timage_size * (bbox[3]-bbox[1]+1), 1)\n",
    "    predict_box[2] = np.minimum(predict_box[0] + sample_w * config.scales[int(s_idx-1)] - 1, img_width) # Be careful when extended to multiple scales\n",
    "    predict_box[3] = np.minimum(predict_box[1] + sample_h * config.scales[int(s_idx-1)] - 1, img_height)\n",
    "\n",
    "    # record result\n",
    "    results[counter, 0] = max_score\n",
    "    results[counter, 1:] = predict_box\n",
    "\n",
    "    # update center coordinates\n",
    "    center_x = np.ceil((predict_box[2]-predict_box[0]+1)/2.0) + predict_box[0] - 1\n",
    "    center_y = np.ceil((predict_box[3]-predict_box[1]+1)/2.0) + predict_box[1] - 1\n",
    "    prev_scale = prev_scale*(1-config.scaleLP) + config.scales[int(s_idx-1)]*config.scaleLP\n",
    "\n",
    "    sample_w = sample_w * prev_scale \n",
    "    sample_h = sample_h * prev_scale\n",
    "\n",
    "    counter = counter + 1\n",
    "    \n",
    "    # show results\n",
    "    pred_bbox = np.copy(img)\n",
    "    cv2.rectangle(pred_bbox, (int(predict_box[0]-1), int(predict_box[1]-1)), (int(predict_box[2]-1), int(predict_box[3]-1)), (0, 255, 0), 3)\n",
    "    np.savetxt('./demo_results/%s/%04d_pred.txt' % (video_name,ii), predict_box.reshape((1,4)).astype(np.int32), fmt='%d', delimiter=',')\n",
    "    plt.imsave('./demo_results/%s/%04d.jpg' % (video_name,ii), pred_bbox)\n",
    "    \n",
    "    #plt.figure(figsize=(12, 6))\n",
    "    #plt.subplot(1, 2, 1)\n",
    "    #plt.imshow(query_bbox)\n",
    "    #plt.subplot(1, 2, 2)\n",
    "    #plt.imshow(pred_bbox)\n",
    "    #plt.pause(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
